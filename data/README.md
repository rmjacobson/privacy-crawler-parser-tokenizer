# Privacy Policy Data

This directory contains all the data consumed or produced by the
modules in this project.  Most of the conents are excluded from
version control in gitignore to avoid bloat in the tracked files list.
You can find these output files in the S3 bucket listed below.  The
exception to this is the inputs directory.

## Inputs
This directory contains all the files consumed by the crawler and
parser-tokenizer:
* `ground_truth_html` contains the HTML files of human-verified privacy
policies that form the "ground truth" of policy verification.  Ensure
that any files you add to this directory are _actually_ privacy
policies.  Note that this directory is version controlled, so any
changes made should be committed if you want them to persist across
cloning.
* `alexa.json` is a JSON file containing the Alexa Top-10,000 sites for
input into the crawler.  This file is not created by this project, but
is generated through an outside script described below.  Note that the
user does not have to run the crawler with _all_ top-N sites, but can
specify how many domains are to be crawled.
* `dictionary.txt` is a text file containing a very large list of
english-language words, one word per line.  The crawler uses it to
determine whether a given link is mostly english text.  Given that the
english language changes rather slowly, the dictionary has been
included in version control to save the user the trouble of finding
their own.
* `rules.json` contains rules that help the tokenizer determine what is
a correct sentence and what is not.  Almost all rules are name-regex
pairs, but HEAD_FRAG is actually a threshold that is dealt with
separately.

## Crawler Output
`crawler_output` contains all output of the crawler, including HTML
files, the stripped text of those HTML files, and a summary containing
trace information and statistics from the operation of the crawler.

## Parser Output
`parser_output` contains all output of the parsing phase of the parser-
tokenizer.  This includes some trace information from the parser in
err.txt and success.txt, as well as CSV files containing the content
and position of every HTML element considered for parsing organized
per-HTML file.

## Tokenizer Output
`tokenizer_output` contains all output of the tokenization phase of the
parser-tokenizer.  This includes a CSV file containing sentences and
their locations for every HTML document considered for tokenization, as
well as statistics of sentence rule violations per-HTML document and
statistics of rule-violations as a whole over the dataset.

## S3 Bucket for Output Files

You can find a .zip archive of all the outputs described above at this
s3 link: https://deep-ner-parsing.s3.us-east-2.amazonaws.com/data.zip.

This data will be updated as the project nears completion, so please
continue to look at this link for more recent data.

## Alexa Top Sites
Alexa Top Sites is a service offered by Amazon to rank websites by
different measures of popularity.  The Alexa Top Sites in the United
States (https://www.alexa.com/topsites/countries/US) forms the basis
of the dataset generated by this project.  `alexa.json`, however, was
generated using the script provided in the following github repository:
https://github.com/everping/aws-alexa-top-sites.  Please reference this
repository if you wish to re-generate the Top Sites list.  Also note
that unless massive changes occur in the online environment, the
_contents_ of the Top Sites list will not change very frequently even
if the _order_ of that list is more variable.  If privacy policies
change due to regulatory efforts, the policies from these sites can be
easily gathered again by the crawler without having to update the Top
Sites list itself.

## What Data Is Not In This Directory?
Most of the modules in this project can be run as standalone scripts to
assist with development and extension.  The outputs of those standalone
runs _*will not*_ be stored in this data directory, and will instead
be left as outputs in whatever directory the user runs the standalone
script from.  Those files are meant for temproary inspection and are
left to the user to remove before committing changes to the project.
